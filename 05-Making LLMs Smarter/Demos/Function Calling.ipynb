{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efdcb39-1abe-4ee5-8647-011fde8e2f2e",
   "metadata": {},
   "source": [
    "# Function calling\n",
    "\n",
    "Function calling is a mechanism for \"extending\" an LLM and empowering it to do things it can't do on its own. For example, with function calling, you can give an LLM access to real-time flight data or real-time weather data, provide it with your current location, or enable it to use the [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula) to compute the distance between two locations. Function calling isn't universally supported among LLMs, but it is supported by foundation models such as `GPT-4o`, `Gemini Flash`, and `Llama`. The following example demonstrates how to implement function calling with `GPT-4o`. It uses just one function, but the same approach works with multiple functions as well.\n",
    "\n",
    "Start by asking `GPT-4o` if it's raining in Knoxville:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c7279-afa6-4aa7-9309-bc9f37625a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide real-time weather updates. To find out if it's currently raining in Knoxville, please check a weather website, app, or local news station for the most accurate information.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='OPENAI_API_KEY')\n",
    "messages = [{ 'role': 'user', 'content': 'Is it raining in Knoxville?' }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2a254-74b9-4e5d-a0bc-7eeeb97c7b39",
   "metadata": {},
   "source": [
    "Of course, it can't answer the question because it has no idea whether it's raining in Knoxville and no way to find out. Let's use function calling to fix that. The first step is to define a local function that uses an external API call to retrieve information about the weather at the specified location. This implementation uses the [OpenWeather API](https://openweathermap.org/api). To run this code, you'll need to plug in your own OpenWeather API key. API keys are free, and you get up to 1,000 calls per day for free, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38481ef4-2588-4273-8aeb-f33c2591868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def get_current_weather(location):\n",
    "    api_key = 'OPENWEATHER_API_KEY'\n",
    "    url = f'https://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=imperial'\n",
    "    response = requests.get(url)\n",
    "    return json.dumps(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0fff7f-b1d2-445b-8501-53d340ec94b5",
   "metadata": {},
   "source": [
    "The next step is to describe the function using a rigid JSON schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc473d2-cbcb-4ee1-8e21-94a563cc3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tool = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': \"\"\"\n",
    "            Retrieves the current weather at the specified location.\n",
    "            Also returns the location's latitude and longitude and the country it's in.\n",
    "            \"\"\",\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The location whose weather is to be retrieved.'\n",
    "                }\n",
    "            },\n",
    "            'required': ['location']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf79fff-4eea-4d9d-a88c-34e5108114bf",
   "metadata": {},
   "source": [
    "For convenience, we'll define a `chat` function that calls `GPT-4o` and makes it aware of the `get_current_weather` function. `chat` returns a list of messages that includes the LLM's response, and if necessary, it uses the `get_current_weather` function to help formulate that response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66730572-2375-42c7-964d-835412cdc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input, messages=None):\n",
    "    if not messages:\n",
    "        # Start a new message thread if none is provided\n",
    "        messages = [{\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant who can fetch information about current weather conditions'\n",
    "        }]\n",
    "    \n",
    "    # Add a message containing the input to this function\n",
    "    message = { 'role': 'user', 'content': input }\n",
    "    messages.append(message)\n",
    "\n",
    "    # Call the LLM  and make it aware of the weather tool\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        tools=[weather_tool]\n",
    "    )\n",
    "    \n",
    "    # If one or more tool calls are required, execute them\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "    \n",
    "            if function_name == 'get_current_weather':\n",
    "                # Get the function argument(s) and call the function\n",
    "                location = json.loads(tool_call.function.arguments)['location']\n",
    "                output = get_current_weather(location)\n",
    "    \n",
    "                # Append the function output to the messages list\n",
    "                messages.append({ 'role': 'function', 'name': function_name, 'content': output })\n",
    "    \n",
    "            else:\n",
    "                raise Exception('Invalid function name')\n",
    "    \n",
    "        # Pass the function output to the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=messages\n",
    "        )\n",
    "    \n",
    "    # Return a message thread containing the LLM's response\n",
    "    messages.append({ 'role': 'assistant', 'content': response.choices[0].message.content })\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db59bd-5dab-4b74-a5d8-dfb70e022d8b",
   "metadata": {},
   "source": [
    "Now use the `chat` function to find out whether it's raining in Knoxville:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dae9e8d-b4f0-4b4e-959b-ab593dd9daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it is not currently raining in Knoxville. The weather is overcast with 100% cloud cover.\n"
     ]
    }
   ],
   "source": [
    "messages = chat('Is it raining in Knoxville?')\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e328e8d-206b-412e-81a7-f1410326f827",
   "metadata": {},
   "source": [
    "One of the features of function calling is that the LLM know what parameters each function accepts, and it know which are required parameters. In the case of the `get`current`weather` function, the LLM knows that it needs a location parameter for the function to be called. Here's what happens if you simply ask fror the weather without specifying a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2edf3cb2-aa6b-41c0-9a57-bdec9369fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check if it's raining, I need to know your current location. Could you please provide that information?\n"
     ]
    }
   ],
   "source": [
    "messages = chat('Is it raining outside?')\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681b13b-1329-4b0b-9bea-e2dd8813de01",
   "metadata": {},
   "source": [
    "The LLM knows it can find out whether it's raining if you provide it with a location, so it asks for the location. You can now follow up with a message that provides that location. It's crucial in this scenario that you include previous messages in the call so the LLM \"remembers\" that it asked for a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243b02a4-1151-4753-ba6c-a46cbbf9946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Knoxville, it is currently overcast with clouds, but there is no indication of rain right now.\n"
     ]
    }
   ],
   "source": [
    "messages = chat('Knoxville', messages)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24141407-c496-4bdd-b25f-252b5ab2812e",
   "metadata": {},
   "source": [
    "Just to be sure, let's ask the LLM a question that doesn't require a function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1724885b-5758-46bb-8d7e-4b589414a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue primarily because of a phenomenon called Rayleigh scattering. As sunlight passes through Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight consists of many colors, each with different wavelengths. \n",
      "\n",
      "Blue light waves are shorter and scatter more than other colors as they strike the molecules in the atmosphere. This scattered blue light is what we see when we look up at the sky during the day. The scattering causes the direct sunlight to lose some of its blue light, which is why the sun appears more yellowish when viewed directly as it gets closer to the horizon, and the sky appears blue most of the time during the day.\n"
     ]
    }
   ],
   "source": [
    "messages = chat('Why is the sky blue?')\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59c3f2-df3a-4273-8e45-9fd09dd8a59f",
   "metadata": {},
   "source": [
    "This is a simple example, but it demonstrates both the power and the mechanics of function calling. For more information on function caling with OpenAI models, see https://platform.openai.com/docs/guides/function-calling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
