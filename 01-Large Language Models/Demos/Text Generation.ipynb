{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with Large Language Models (LLMs)\n",
    "\n",
    "`GPT-4o` is one of several sophisticated large language models (LLMs) built by [OpenAI](https://openai.com/), a San Francisco-based company whose mission is to \"ensure that artificial general intelligence benefits all of humanity.\" `GPT-4o` can generate human-like prose by responding to prompts written in the [Chat Markup Language](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt), or ChatML for short. Here are few examples demonstrating how to leverage `GPT-4o`'s text-generation capabilities. Start by asking `GPT-4o` to describe molecular biology in the style of Dr. Seuss. Run this cell several times and you'll get a different result each time. Set `temperature` to 0, however, and the results will be the same most of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of the cell, where the wee enzymes dwell,  \n",
      "Lived molecules grand, with a story to tell.  \n",
      "With wibbles and wobbles and twists all around,  \n",
      "In the nucleus townhouse, DNA could be found.  \n",
      "\n",
      "Now DNA, you see, is a marvelous thing,  \n",
      "A helical ladder, with bases that cling.  \n",
      "A, T, C, and G, all in a line,  \n",
      "In nuclear splendor, they truly do shine.  \n",
      "\n",
      "Proteins, my friend, are the workers you'll meet,  \n",
      "Built from amino acids, a structural feat!  \n",
      "They wobble and weave in three dimensions and more,  \n",
      "Folding with flair, oh the shapes they explore!  \n",
      "\n",
      "Messenger RNA, with its ribbon so bright,  \n",
      "Carries the message from morning to night.  \n",
      "From nucleus city to the ribosome's door,  \n",
      "Translating instructions, to protein they soar.  \n",
      "\n",
      "Ribosomes, oh joy, are the factories keen,  \n",
      "Constructing proteins like a sewing machine!  \n",
      "They take mRNA with a tick and a tock,  \n",
      "And stitch together chains, by the clock!  \n",
      "\n",
      "Enzymes are zipping, unzipping with ease,  \n",
      "Speeding reactions, as quick as a breeze.  \n",
      "They're catalysts, clever, in every cell nook,  \n",
      "So swiftly they work, you'll not need a book.  \n",
      "\n",
      "So in the world of the cell, things are never too plain,  \n",
      "With molecules dancing, it's all quite insane!  \n",
      "A Seussian tale in the realms so small,  \n",
      "Where life's little wonders do astound us all!  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='OPENAI_API_KEY')\n",
    "\n",
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'content': 'Describe molecular biology in the style of Dr. Seuss'\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can richen the UI experience by streaming the response. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of Cells, all small and unseen,  \n",
      "Lies a world of wonders, so lively and keen.  \n",
      "With creatures named Genes, and Proteins, an art,  \n",
      "Molecular Biology's where they all start.  \n",
      "\n",
      "Oh, the DNA helix, with twists bold and bright,  \n",
      "Carries codes in its spirals, just hidden from sight.  \n",
      "A-T and C-G, they pair with such flair,  \n",
      "Creating blueprints for life, a plan rare and rare.  \n",
      "\n",
      "Then come the Ribosomes, round as a ball,  \n",
      "Reading those codes, giving life to the call.  \n",
      "They stitch up Amino Acids, like beads on a thread,  \n",
      "Building Proteins, life’s builders, on which all is fed.  \n",
      "\n",
      "The Proteins, they fold, in shapes wild and fun,  \n",
      "Doing jobs in the cells, yes, each and every one.  \n",
      "From enzymes to transporters, their work is routine,  \n",
      "Keeping life bustling, in this microscopic scene.  \n",
      "\n",
      "And let's not forget Mitochondria's might,  \n",
      "The powerhouse cells, generating light.  \n",
      "They churn out the energy, like sunbeams they glow,  \n",
      "Fueling the cells, making life grow and grow.  \n",
      "\n",
      "So here's to the marvelous, miniature spree,  \n",
      "Of molecules tiny, that make you and me.  \n",
      "In the whimsical world, where small things unfold,  \n",
      "Molecular tales of life, bright and bold!"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational context\n",
    "\n",
    "Messages transmitted to `GPT-4o` use the Chat Markup Language. ChatML exists so that the context of a conversation can be preserved across calls. To demonstrate, ask the LLM what its name is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeff! I don’t have a personal name, but you can call me Assistant. How can I help you today?"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'content': \"My name is Jeff. What's your name?\"\n",
    "}]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    " \n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeff! My name is LISA. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': \"My name is Jeff. What's your name?\"\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    " \n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can be as specific as you’d like with `system` messages, even saying \"If you don’t know the answer to a question, say I don’t know.\" You can also prescribe a persona. Replace \"friendly\" with \"sarcastic\" in the message from system and run the code again. The response may be \"Oh, hi Jeff, I’m LISA. You can call me whatever you'd like, but don’t call me late for dinner.\" Run the code several times and there’s no end to the colorful responses you’ll receive.\n",
    "\n",
    "ChatML's greatest power lies in persisting context from one call to the next. As an example, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeff! My name is LISA. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': \"My name is Jeff. What's your name?\"\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then follow up immediately with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I don't have access to personal information like your name. If you'd like, you can tell me your name, and I'll be happy to address you that way!"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is my name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM will respond with something along the lines of \"I'm sorry, but I don’t have access to that information.\" But now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Jeff. If you have any questions or need assistance, feel free to ask!"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a friendly assistant named LISA.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': \"My name is Jeff. What's your name?\"\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'Hello Jeff, my name is LISA. Nice to meet you!'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is my name?'\n",
    "    }\n",
    "]\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get it? Calls to `GPT-4o` are stateless. If you give `GPT-4o` your name in one call and ask it to repeat your name in the next call, it has no clue. But with ChatML, you can provide past responses as context for the current call. You can build a conversational assistant simply by repeating the last few prompts and responses in each call to `GPT-4o`. The further back you go, the longer the assistant's \"memory\" will be. Here's a `chat` function that enables that by accepting previous messages as input and returning a messages list with the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input, messages=None):\n",
    "    if not messages:\n",
    "        messages = [{ 'role': 'system', 'content': 'You are a friendly assistant named LISA' }]\n",
    "    \n",
    "    message = { 'role': 'user', 'content': input }\n",
    "    messages.append(message)\n",
    "\n",
    "    client = OpenAI(api_key='OPENAI_API_KEY')\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Return a message thread containing the LLM's response\n",
    "    messages.append({ 'role': 'assistant', 'content': response.choices[0].message.content })\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `chat` function to tell the LLM your name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jeff! My name is LISA. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = chat(\"My name is Jeff. What's your name?\")\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then ask it what your name is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Jeff. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "messages = chat(\"What is my name?\", messages=messages)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "LLMs don't work with words; they work with *tokens*. Tokenization plays an important role in Natural Language Processing. Neural networks can’t process text, at least not directly; they only process numbers. Tokenization converts words into numbers that a deep-learning model can understand. When `GPT-4o` generates a response by predicting a series of tokens, the tokenization process is reversed to convert the tokens into human-readable text.\n",
    "\n",
    "OpenAI LLMs use a form of tokenization called [Byte-Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (BPE), which was developed in the 1990s as a mechanism for compressing text. Today, it is widely used in the NLP space. Here’s how `GPT-4o` BPE-tokenizes the phrase \"fourscore and seven years ago:\"\n",
    "\n",
    "![](Images/bpe.png)\n",
    "\n",
    "As a rule of thumb, 3 words on average translate to about 4 BPE tokens. That’s important because LLMs limit the number of tokens in each API call. The maximum token count is controlled by a parameter named `max_tokens`. For `GPT-4o`, the default is 4,096 tokens or about 3,000 words. `GPT-4o` has a context window size of 128K, so the upper limit is 128K. That's enough to pass in a document that's a few hundred pages long. If the number of tokens generated exceeds `max_tokens`, then either the call will fail or the response will be truncated.\n",
    "\n",
    "You can compute the number of tokens generated from a text sample with help from a Python package named [`tiktoken`](https://pypi.org/project/tiktoken/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 tokens\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    " \n",
    "text = '''\n",
    "    Jeff loves to build and fly model jets. He built his first\n",
    "    jet, a BVM BobCat, in 2007. After that, he built a BVM Bandit,\n",
    "    a Skymaster F-16, and a Skymaster F-5. The latter two are 1/6th\n",
    "    scale models of actual fighter jets. Top speed is around 200 MPH.\n",
    "    '''\n",
    " \n",
    "encoding = tiktoken.encoding_for_model('gpt-4o')\n",
    "num_tokens = len(encoding.encode(text))\n",
    "print(f'{num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can estimate the token count for an entire `messages` array with the following code, which was adapted comments and all from the [OpenAI documentation](https://platform.openai.com/docs/guides/chat/introduction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 tokens\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    " \n",
    "for message in messages:\n",
    "    num_tokens += 4 # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "    for key, value in message.items():\n",
    "        num_tokens += len(encoding.encode(value))\n",
    "        if key == 'name':  # if there's a name, the role is omitted\n",
    "            num_tokens += -1 # role is always required and always 1 token\n",
    "             \n",
    "num_tokens += 2 # every reply is primed with <im_start>assistant\n",
    "print(f'{num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of reasons to be aware of the token count in each call. First, you’re charged by the token for input and output. The larger the `messages` array and the longer the response, the more you pay. Second, when using the messages array to provide context from previous calls, you have a finite amount of space to work with. It's common practice to pick a number – say, 10 or 20 – and limit the context from previous calls to that number of messages, or to programmatically compute the number of tokens that a conversation comprises and include as many messages as `max_tokens` will allow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing\n",
    "\n",
    "`GPT-4o` can perform many NLP tasks such as sentiment analysis and neural machine translation (NMT) without further training. Here's an example that translates text from English to French:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff aime construire et piloter des avions à réaction miniatures. Il a construit son premier avion, un BVM BobCat, en 2007. Après cela, il a construit un BVM Bandit, un Skymaster F-16, et un Skymaster F-5. Les deux derniers sont des modèles à l'échelle 1/6e de véritables avions de combat. Leur vitesse maximale est d'environ 200 MPH.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'Translate the following text from English to French: {text}'\n",
    "messages = chat(prompt)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples demonstrate how to use `GPT-4o` for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the review is positive.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "    Indicate whether the following review's sentiment is positive or\n",
    "    negative: Great food and excellent service.\n",
    "    '''\n",
    "\n",
    "messages = chat(prompt)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the review is negative.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "    Indicate whether the following review's sentiment is positive or\n",
    "    negative: Long lines and poor customer service.\n",
    "    '''\n",
    "\n",
    "messages = chat(prompt)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a text-classification task. LLMs can classify text in other ways, too. The next two examples demonstrate how to use `GPT-4o` as a spam filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This email is not spam. It appears to be an internal communication related to a workplace or professional activity, specifically about attending a code review meeting.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "    Indicate whether the following email is spam or not spam:\n",
    "    Please plan to attend the code review at 2:00 p.m. this afternoon.\n",
    "    '''\n",
    "\n",
    "messages = chat(prompt)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This email is likely spam. It promotes the purchase of prescription medications online with promises of saving money, which is a common characteristic of spam emails. Additionally, unsolicited emails offering such deals can often be associated with scams or disreputable sources.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "    Indicate whether the following email is spam or not spam:\n",
    "    Order prescription meds online and save $$$.\n",
    "    '''\n",
    "\n",
    "messages = chat(prompt)\n",
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A practical use for LLMs is parsing freeform address fields and generating structured data. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"Street Address\": \"11 Aviation Avenue\",\n",
      "    \"City\": \"Charlottetown\",\n",
      "    \"State\": \"Prince Edward Island\",\n",
      "    \"Country\": \"Canada\",\n",
      "    \"Postal Code\": \"C1E 0A1\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Roche Molecular Systems, Inc.\",\n",
      "    \"Street Address\": \"4300 Hacienda Drive\",\n",
      "    \"City\": \"Pleasanton\",\n",
      "    \"State\": \"California\",\n",
      "    \"Country\": \"United States\",\n",
      "    \"Postal Code\": \"94588\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Cross Research S.A.\",\n",
      "    \"Street Address\": \"Phase I Unit, Via F.A. Giorgioli 14\",\n",
      "    \"City\": \"Arzo\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Switzerland\",\n",
      "    \"Postal Code\": \"6864\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Wasdell Group, Wasdell Packaging Ltd\",\n",
      "    \"Street Address\": \"Unit 1-8, Euroway Industrial Estate, Blagrove\",\n",
      "    \"City\": \"Swindon\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"United Kingdom\",\n",
      "    \"Postal Code\": \"SN5 8YW\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"Street Address\": \"Policlinico Gemelli, 4th Floor, Wing J, Largo Gemelli 8\",\n",
      "    \"City\": \"Rome\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Italy\",\n",
      "    \"Postal Code\": \"00168\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Academisch Ziekenhuis Maastricht, CDL Stamcellaboratorium\",\n",
      "    \"Street Address\": \"P. Debyelaan 25 5e\",\n",
      "    \"City\": \"Maastricht\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Netherlands\",\n",
      "    \"Postal Code\": \"6229 HX\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Wintellect Brussels\",\n",
      "    \"Street Address\": \"Leuvensesteenweg 555\",\n",
      "    \"City\": \"Marken Benelux\",\n",
      "    \"State\": \"\",\n",
      "    \"Country\": \"Belgium\",\n",
      "    \"Postal Code\": \"1930\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"Street Address\": \"215-31, Miyos\",\n",
      "    \"City\": \"Maihara\",\n",
      "    \"State\": \"Shiga-Ken\",\n",
      "    \"Country\": \"Japan\",\n",
      "    \"Postal Code\": \"215-31\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Healthcare Logistics Australia\",\n",
      "    \"Street Address\": \"7 Dolerite Way\",\n",
      "    \"City\": \"Pemulwuy\",\n",
      "    \"State\": \"New South Wales\",\n",
      "    \"Country\": \"Australia\",\n",
      "    \"Postal Code\": \"2145\"\n",
      "}\n",
      "{\n",
      "    \"Name\": \"Suncoast Research\",\n",
      "    \"Street Address\": \"2128 W Flagler St, Suite 101\",\n",
      "    \"City\": \"Miami\",\n",
      "    \"State\": \"Florida\",\n",
      "    \"Country\": \"United States\",\n",
      "    \"Postal Code\": \"33135\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "addresses = [\n",
    "    '11 Aviation Avenue, Charlottetown, PE C1E 0A1, Canada',\n",
    "    'Roche Molecular Systems, Inc., 4300 Hacienda Drive, Pleasanton, CA 94588, US',\n",
    "    'Cross Research S.A., Phase I Unit, Via F.A. Giorgioli 14, Arzo, 6864, CH',\n",
    "    'Wasdell Group, Wasdell Packaging Ltd Unit 1-8, Euroway Industrial Estate, Blagrove, Swindon, SN5 8YW, GB',\n",
    "    'Policlinico Gemelli, 4th Floor, Wing J, Largo Gemelli 8, Rome, 00168, IT',\n",
    "    'Academisch Ziekenhuis Maastricht, CDL Stamcellaboratorium, P. Debyelaan 25 5e, Maastricht, 6229 HX, NL',\n",
    "    'Wintellect Brussels, Leuvensesteenweg 555, Marken Benelux, 1930, BE',\n",
    "    'SCM department, AstraZeneca K.K., Maihara Factory, AstraZeneca K.K., 215-31, Miyos, Shiga-Ken, 215-31, JP',\n",
    "    'Healthcare Logistics Australia, 7 Dolerite Way, Pemulwuy NSW 2145, AU',\n",
    "    'Suncoast Research, 2128 W Flagler St, Suite 101, Mami, FL, 33135, US'\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key='OPENAI_API_KEY')\n",
    "\n",
    "for address in addresses:\n",
    "    prompt = f'''\n",
    "        Parse the freeform address below into fields and return a JSON\n",
    "        representation that uses the following format. Convert country\n",
    "        abbreviations such as \"CA\" into country names such as \"Canada\"\n",
    "        and state abbreviations such as \"CA\" into state names such as\n",
    "        \"California.\" Leave unknown fields blank. Also correct any\n",
    "        obvious misspellings. Return JSON only and do not use markdown.\n",
    "    \n",
    "        {{\n",
    "            \"Name\": \"Recipient\",\n",
    "            \"Street Address\": \"Street address\",\n",
    "            \"City\": \"City, town, etc.\",\n",
    "            \"State\": \"State, province, region, territory, canton, county, department, länder, or prefecture\",\n",
    "            \"Country\": \"Country name\",\n",
    "            \"Postal Code\": \"Postal code\"\n",
    "        }}\n",
    "    \n",
    "        Address: {address}\n",
    "        '''\n",
    "\n",
    "    messages = [{ 'role': 'user', 'content': prompt }]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        response_format={ 'type': 'json_object' }\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GPT-4o`'s 128K context-window size enables it to ingest large documents for summarization or other purposes. Let's see what it can do with Microsoft's 2022 annual report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Microsoft 2022 Annual Report Summary\n",
       "\n",
       "## Chairman's Message\n",
       "\n",
       "**Satya Nadella** highlights the rapid technological advancements amidst global economic and political changes, emphasizing Microsoft's mission to empower people and organizations worldwide.\n",
       "\n",
       "### Key Points\n",
       "\n",
       "- **Technological Era**: With the rise in digital transformation, Microsoft is focused on helping industries use technology to address current challenges and growth opportunities.\n",
       "- **Customer Impact**: Examples include:\n",
       "  - **Ferrovial**: Enhancing roads for autonomous transport using Microsoft’s cloud.\n",
       "  - **Peace Parks Foundation**: Using Dynamics 365 and Power BI for funding and conservation efforts.\n",
       "  - **Kawasaki Heavy Industries**: Creating an industrial metaverse with Azure IoT and HoloLens.\n",
       "  - **Globo (Brazil)**: Empowering employees to create solutions with Power Platform.\n",
       "  - **Ørsted**: Utilizing Microsoft Intelligent Data Platform for predictive turbine maintenance.\n",
       "\n",
       "### Financial Highlights\n",
       "\n",
       "- **Record Revenue**: $198 billion in revenue, $83 billion in operating income.\n",
       "- **Microsoft Cloud**: Surpassed $100 billion in annualized revenue.\n",
       "\n",
       "## Responsibility\n",
       "\n",
       "Microsoft commits to aligning its innovations with global economic and social issues towards a more inclusive, equitable, sustainable, and trusted future.\n",
       "\n",
       "### Key Initiatives\n",
       "\n",
       "- **Inclusive Economic Growth**: Reached over 23 million people with digital skills training. Aim to equip 10 million underserved with digital economy skills by 2025.\n",
       "- **Cybersecurity Workforce**: Plan to skill 250,000 people in the US by 2025.\n",
       "- **Nonprofit Support**: $3.2 billion in technology assistance to nonprofits, aiming to double outreach in five years.\n",
       "\n",
       "## Sustainability and Trust\n",
       "\n",
       "### Environmental Goals\n",
       "\n",
       "- **Carbon Negative by 2030**: Released a sustainability report to track progress.\n",
       "- **Water and Waste Initiatives**: Launched projects for water replenishment and waste diversion, protecting more land than used by 2025.\n",
       "\n",
       "### Trust and Technology\n",
       "\n",
       "- **Privacy and Security**: Committed to strong privacy laws and analyzing 43 trillion security signals daily.\n",
       "- **Responsible AI**: Published standards and tools to ensure AI aligns with their principles.\n",
       "\n",
       "## Future Opportunities\n",
       "\n",
       "Microsoft envisions doubling the tech's GDP percentage and integrating it across all industries, evolving towards every company becoming a software company.\n",
       "\n",
       "## Market Leadership\n",
       "\n",
       "### Segments and Innovations\n",
       "\n",
       "1. **Azure**: Expanding datacenter regions, enhancing cloud services, supporting hybrid consistency.\n",
       "2. **Data and AI**: Comprehensive data offerings with Microsoft Intelligent Data Platform, Microsoft Purview, and Azure OpenAI Service.\n",
       "3. **Modern Work**: Leading hybrid work solutions with Microsoft Teams (270 million+ users) and Microsoft Viva.\n",
       "4. **Consumer Tech**: Launch of Windows 11 and new Surface devices; strength in Xbox and LinkedIn offerings.\n",
       "\n",
       "### Financial Metrics\n",
       "\n",
       "- **Share Repurchases**: Executed buybacks under $60 billion program commenced in 2021.\n",
       "- **Dividend Policy**: Regular quarterly increases, reflecting confidence in cash flow and growth potential.\n",
       "\n",
       "## Strategic Business Segments\n",
       "\n",
       "1. **Productivity and Business Processes**: Growth from Office 365 and LinkedIn.\n",
       "2. **Intelligent Cloud**: Strong performance in Azure and other cloud services.\n",
       "3. **More Personal Computing**: Gains in Windows, Devices, and Xbox markets.\n",
       "\n",
       "## Governance and Leadership\n",
       "\n",
       "- **Board and Management**: Ensures transparent governance with a focus on environmental, social, and governance (ESG) responsibilities.\n",
       "\n",
       "Microsoft remains steadfast in its mission to transform industries, manage digital risks, and lead with purpose-driven innovation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "with open('Data/annual-report.txt', 'r') as file:\n",
    "    report = file.read()\n",
    "\n",
    "prompt = f'''\n",
    "    Summarize the following annual report from Microsoft. Use\n",
    "    markdown formatting in your output:\n",
    "\n",
    "    {report}\n",
    "    '''\n",
    "\n",
    "messages = chat(prompt)\n",
    "output = messages[-1]['content']\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's see how Gemini 1.5 Flash summarizes the same report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This document is a corporate filing by Microsoft Corporation, likely a section of their 10-K report, which is an annual filing with the Securities and Exchange Commission (SEC). \n",
       "\n",
       "Here is a summary of the document's key points:\n",
       "\n",
       "**Financial Statements**\n",
       "\n",
       "* **Opinion on the Financial Statements:** Deloitte & Touche LLP, the independent auditor, expressed an unqualified opinion on Microsoft's consolidated financial statements for the year ended June 30, 2022. This means the statements are considered to be presented fairly, in all material respects, in accordance with generally accepted accounting principles in the United States.\n",
       "* **Critical Audit Matters:** The audit report identified two critical audit matters:\n",
       "    * **Revenue Recognition:**  Deloitte & Touche LLP performed extensive procedures to evaluate Microsoft's judgment in determining revenue recognition for complex customer agreements. \n",
       "    * **Income Taxes – Uncertain Tax Positions:** The audit report focused on the evaluation of management's estimates of uncertain tax positions related to unresolved transfer pricing issues with the IRS. \n",
       "* **Management's Report on Internal Control Over Financial Reporting:**  Microsoft's management concluded that the Company's internal control over financial reporting was effective as of June 30, 2022. \n",
       "* **Report of Independent Registered Public Accounting Firm on Internal Control Over Financial Reporting:** Deloitte & Touche LLP, the independent auditor, expressed an unqualified opinion on Microsoft's internal control over financial reporting as of June 30, 2022.  This means the Company has a strong system of internal controls in place.\n",
       "\n",
       "**Other Information**\n",
       "\n",
       "* **Directors and Executive Officers:** The report lists the current board of directors and executive officers of Microsoft Corporation.\n",
       "* **Investor Relations Contact Information:** This section provides details for contacting Microsoft's Investor Relations department. \n",
       "* **Attending the Annual Meeting:** This section provides information on how shareholders can attend the 2022 Annual Shareholders Meeting, which was held virtually.\n",
       "* **Registered Shareholder Services:** This section provides contact information for Computershare, the transfer agent, who handles shareholder-related services.\n",
       "* **Environmental, Social, and Governance (ESG)/Corporate Social Responsibility:** Microsoft highlights its commitment to ESG principles and its ongoing efforts in corporate social responsibility.\n",
       "\n",
       "**Overall, this document is a significant filing for investors and other stakeholders, providing assurance about the accuracy of Microsoft's financial statements and their overall business practices.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(prompt)\n",
    "output = response.text\n",
    "\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
